{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On reprend les données Boston du précédent TP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ajuster sur les données Boston une forêt aléatoire composée de 10 arbres avec un nombre maximal de 4 variables considérées à chaque noeud (consulter la [doc](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RF = RandomForestRegressor(#### TODO ####)\n",
    "#### TODO ####    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> L'attribut `.estimators_` contient la structure des 10 arbres de la forêt. Calculer les prédictions sur les mêmes données à partir de ces 10 arbres. Comparer avec la prédiction directement fournie  par la méthode `predict` de `RandomForestRegressor`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict_list = [#### TODO ####]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(#### TODO ####)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.predict(X_Bost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les performances de prévision sont évaluées par défaut dans sckit-learn via le score $R^2$ (voir le précédent TP). La démarche standard est de calculer ce score par validation croisée sur des échantillons tests obtenus par K-fold (score test). Pour les Bagged Tree et les Random Forest, il est possible de se passer de validation croisée en calculant ce score par la méthode out-of-bag (score OOB). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On souhaite comparer les scores OOB et les scores de test (via une validation croisée K-fold) pour des RF avec un nombre d'arbres entre 5 et 100 (`n_estimators=`). On demande le calcul du score OOB dans la forêt aléatoire avec l'argument `oob_score = True`. Pour  évaluer le score sur un échantillon test, on pourra utiliser la fonction `GridSearchCV`.   \n",
    "> Comparer la vitesse d'exécution de chaque approche et faire un graphique pour comparer les scores.   \n",
    "> Expliquer pourquoi il est naturel que le score OOB soit plus faible lorsque le nombre d'arbres est faible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores de test\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "\n",
    "start = time()\n",
    "\n",
    "my_kfold = #### TODO ####\n",
    "\n",
    "tree_range = range(5,100)\n",
    "\n",
    "tuned_parameters = #### TODO ####\n",
    "\n",
    "Cart_grid = GridSearchCV(#### TODO ####)\n",
    "\n",
    "Cart_grid.fit(X_Bost,Y_Bost)\n",
    "test_error=#### TODO ####\n",
    "print(str(time() - start)+ \" sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores oob\n",
    "\n",
    "start = time()\n",
    "oob_error = []\n",
    "for ntree in tree_range:\n",
    "    #### TODO ####\n",
    "print(str(time() - start)+ \" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peu d'arbres implique une foret calculée avec vraiment peu d'arbres pour OOB et donc un score potentiellement plus faible que le score de la foret complète évaluée sur l'échantillon test.\n",
    "\n",
    "Par ailleurs, lorsque la foret contient peu d'arbres, on note que certaines observations ne sont jamais dans les échantillons OOB (d'où les warnings).\n",
    "\n",
    "Lorsque le nombre d'arbres est suffisamment grand, le score OOB finit par dépasser le score évalué via l'échantillon test. Ce phénomène peut s'expliquer par le fait que dans le cas OOB, nous utilisons toutes les données pour construire la forêt aléatoire, alors que dans le cas de l'évaluation sur l'échantillon test, les forêts aléatoires ne sont construites que sur les 4/5 ième des données, il est donc naturel que les performances soient supérieures dans le premier cas.\n",
    "\n",
    "Pour ce qui concerne maintenant les performances de la méthode OOB, en tant que méthode d'estimation de l'erreur de généralisation, la littérature récente (voir par exemple les conclusions de [cette étude](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0201904)) indique que cette méthode tend à surestimer l'erreur de généralisation. Il s'agit d'un sujet de recherche encore ouvert. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Plutôt que d'utiliser le score $R^2$, on peut choisir un autre score, par exemple estimer l'erreur quadratique de prédiction de la forêt, et là aussi de deux façons : \n",
    "- en utilisant les échantillons OOB (avec le champ `.oob_prediction_` de la forêt ajustée) ;\n",
    "- ou plus classiquement par validation croisée K-fold en utilisant la fonction `GridSearchCV`. \n",
    ">\n",
    "> Reprendre la comparaison précédente avec ce nouveau score. On pourra utiliser le scorer `neg_mean_squared_erro` de sklearn (voir la [doc](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)). On peut de plus préciser le score souhaité dans la fonction `GridSearchCV` grâce à l'option `scoring` (voir [ici](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> On souhaite optimiser les performances du modèle de forêts aléaoires (basé sur 50 arbres). Pour cela :\n",
    "> - découper l'échantillon initial en train - test (80% -  20%)\n",
    "> - sur l'échantillon d'apprentissage, déterminer via une estimation des erreurs OOB : \n",
    "        - le meilleur paramètre `max_leaf_nodes` (sur la grille `maxnode` proposée ci-dessous)\n",
    "        - le meilleur paramètre `max_features` (autour de p/3 où p est le nombre de features initiales).\n",
    "> - pour ces choix de paramètres, ajuster le modèle final sur l'échantillon d'apprentissage\n",
    "> - évaluer la qualité prédictive sur l'échantillon test\n",
    "\n",
    "Noter que la fonction `GridSearchCV`, qui par définition effectue des validations croisées, n'est pas adaptée pour cette recherche de paramètres par évaluation de l'erreur out of bag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Bost_train, X_Bost_test, y_Bost_train, y_Bost_test =train_test_split(X_Bost,Y_Bost,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "maxnodes = [2,4,6,8,10,15,20,30,50,100,200,300,400,500,800]\n",
    "maxfeatures=range(2,10)\n",
    "\n",
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Faire de même pour des bagging trees et comparer les performances des deux modèles ainsi ajustés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "maxnodes = [2,4,6,8,10,15,20,30,50,100,200,300,400,500,800]\n",
    "maxfeatures=range(2,10)\n",
    "\n",
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance des variables dans une forêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Importance au sens de Gini\n",
    "\n",
    "> Pour le modèle de forêt aléatoire sélectionné ci-dessus, afficher les [importances des variables au sens de Gini](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importance par permutation OOB\n",
    "\n",
    "Nous allons maintenant écrire une fonction pour calculer l'importance par permutation des variables en utilisant l'échantillon out of bag. \n",
    "Il est possible de retrouver les indices de observations contenues dans l'échantillon bootstrap et dans l'échantillon out of bag associé à chaque arbre en utilisant les fonctions privées `_generate_sampled_indices` et `_generate_unsampled_indices` de la fonction `_forest` (dont le code source est disponible sur github [ici](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/_forest.py)).\n",
    "On commence par charger ces deux fonctions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble._forest import _generate_unsampled_indices\n",
    "from sklearn.ensemble._forest import _generate_sample_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction prend en arguments : \n",
    "- random_state : un entier qui encodre le tirage aléatoire de l'échantillon bootstrap (associé pour nous à un arbre)\n",
    "- n_samples : nombre d'observations dans l'échantillon d'apprentissage\n",
    "- n_samples_bootstrap : = nombre d'observations dans les échantillons bootstrap, égal à n_samples pour le cas qui nous intéresse ici.\n",
    "\n",
    "Le `random_state` est un attribut disponible pour chaque arbre de la forêt. Par exemple pour le premier arbre :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.estimators_[0].random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi retrouver pour le premier arbre la liste des indices des observations dans l'échantillon bootstrap et dans l'échantillon out of bag :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boot_indices = _generate_sample_indices(RF.estimators_[0].random_state,shape(X_Bost)[0],shape(X_Bost)[0])\n",
    "boot_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_indices = _generate_unsampled_indices(RF.estimators_[0].random_state,shape(X_Bost)[0],shape(X_Bost)[0])\n",
    "oob_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> vérifier que tous les indices sont bien présents dans l'un ou l'autre des deux échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ecrire maintenant une fonction `importance_permutation_oob` qui prend en arguments une forêt aléatoire et les données d'apprentissage X,y (surlesquelles la forêt a été ajustée) et qui renvoie les importances par permutation calculées sur les échantillons OOB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importance_permutation_oob(forest,X, y ):\n",
    "    #### TODO ####\n",
    "    \n",
    "    return mean_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Appliquer cette fonction sur les données Boston."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importance par permutation sur échantillon de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> La fonction [`permutation_importance`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance)\n",
    " permet de calculer l'importance, mais en permutant cette fois les variables d'un autre échantillon c'est à dire typiquement un échantillon test. Appliquer cette fonction sur la forêt aléatoire ajustée sur les données Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">  Représenter sur un même graphique en bâtons les 3 types d'importance, en les renormalisant pour chacune d'elle prenne la valeur 100 sur la variable d'importance maximale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur cet exemple, les trois classements de variables (obtenus en classant les variables par importance décroissante) sont comparables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifieur par forêt aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ajuster un classifieur par forêt aléatoire (contenant 100 arbres) sur le jeu de données SPAM en sélectionnant le paramètre `max_features` via l'erreur OOB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=  #### TODO ####\n",
    "data_path = file_path + \"spambase.txt\"\n",
    "features_names = pd.read_csv(#### TODO ####)\n",
    "data_path = file_path + \"spambase.data\"\n",
    "Spam_data = pd.read_csv(#### TODO ####)\n",
    "X_Spam = Spam_data.values[:,0:57]\n",
    "Y_Spam = Spam_data.values[:,57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Représenter l'importance de Gini pour le modèle sélectionné (uniquement pour les 20 principales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive Feature Elimination (RFE)\n",
    "\n",
    "Lorsque le prédicteur est construit sur un grand nombre de variables, ce dernier peut être sujet à un effet de sur-apprentissage. Pour améliorer les performances du modèle, on essaye alors de réduire le nombre de variables utilisées. \n",
    "\n",
    "La méthode RFE (recursive feature elimination) est une méthode de sélection de variables de type \"backward\" : partant du plus grand modèle, on retire progressivement les variables les moins \"intéressantes\" du modèle jusqu'à obtenir une erreur de test minimale.\n",
    "\n",
    "Noter que cette stratégie se distingue de celle qui consiste à réduire la dimension en amont de l'apprentissage supervisé, en effectuant par exemple une analyse en composantes principales sur les données brutes. Dans ce dernier cas, on crée en effet de nouvelles variables pour tenter de synthétiser l'information disponible.\n",
    "\n",
    "\n",
    "> Pour le jeu de données SPAM, implémenter la méthode RFE pour la forêt aléatoire en considérant comme critère de sélection l'importance de type GINI ( `.feature_importances_`). \n",
    ">\n",
    ">    - Initialisation :  ajuster une forêt aléatoire sur le jeu de données complet  (avec toutes les variables)\n",
    ">    - Tant qu'il reste des variables :\n",
    ">        - Calculer les importances sur la forêt courante\n",
    ">        - Retirer la (les) variable(s) la (les) moins importante(s)\n",
    ">        - Ajuster sur les données une forêt aléatoire en utilisant les variables restantes\n",
    ">        - Calculer l'erreur de test de cette forêt\n",
    ">    - A partir des erreurs de test évaluées sur la suite (emboitée) des modèles parcourus, indiquer le groupe de variables finalement sélectionné.\n",
    ">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### TODO ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(oob_score_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur cet exemple, on voit cependant que la méthode RFE ne permet malheureusement pas d'améliorer les performances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
